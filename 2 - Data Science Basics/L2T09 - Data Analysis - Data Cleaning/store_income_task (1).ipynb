{"cells":[{"source":"## Compulsory Task \n\nIn this compulsory task you will clean the country column and parse the date column in the **store_income_data_task.csv** file.","metadata":{"id":"lqt_yzRy16Wj"},"id":"ec01b62b-4a5b-41a8-851d-c237a9bcb46e","cell_type":"markdown"},{"source":"# Import libraries\nimport numpy as np\nimport pandas as pd\nimport fuzzywuzzy\nfrom fuzzywuzzy import fuzz, process\nimport chardet\nimport datetime","metadata":{"executionCancelledAt":null,"executionTime":46,"lastExecutedAt":1698429961733,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import libraries\nimport numpy as np\nimport pandas as pd\nimport fuzzywuzzy\nfrom fuzzywuzzy import fuzz, process\nimport chardet\nimport datetime"},"cell_type":"code","id":"38c9cc20-f49a-4316-87e2-999f98bc39fd","execution_count":24,"outputs":[]},{"source":"# Load up store_income_data.csv\nstore_income_df = pd.read_csv(\"store_income_data_task.csv\")","metadata":{"id":"vBP3WN2O16Wp","executionCancelledAt":null,"executionTime":44,"lastExecutedAt":1698429961777,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load up store_income_data.csv\nstore_income_df = pd.read_csv(\"store_income_data_task.csv\")"},"id":"fbd4b8fe-1ea7-40b5-8017-280ab9054d02","cell_type":"code","execution_count":25,"outputs":[]},{"source":"store_income_df.head()","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1698429961831,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"store_income_df.head()","outputsMetadata":{"0":{"height":207,"type":"dataFrame"}}},"cell_type":"code","id":"4b3e078f-4130-4ddc-93fd-c3f455ea7857","execution_count":26,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"id","type":"integer"},{"name":"store_name","type":"string"},{"name":"store_email","type":"string"},{"name":"department","type":"string"},{"name":"income","type":"string"},{"name":"date_measured","type":"string"},{"name":"country","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"id":1,"store_name":"Cullen/Frost Bankers, Inc.","store_email":null,"department":"Clothing","income":"$54438554.24","date_measured":"4-2-2006","country":"United States/"},{"index":1,"id":2,"store_name":"Nordson Corporation","store_email":null,"department":"Tools","income":"$41744177.01","date_measured":"4-1-2006","country":"Britain"},{"index":2,"id":3,"store_name":"Stag Industrial, Inc.","store_email":null,"department":"Beauty","income":"$36152340.34","date_measured":"12-9-2003","country":" United States"},{"index":3,"id":4,"store_name":"FIRST REPUBLIC BANK","store_email":"ecanadine3@fc2.com","department":"Automotive","income":"$8928350.04","date_measured":"8-5-2006","country":"Britain/"},{"index":4,"id":5,"store_name":"Mercantile Bank Corporation","store_email":null,"department":"Baby","income":"$33552742.32","date_measured":"21-1-1973","country":" United Kingdom"}]},"total_rows":5,"truncation_type":null},"text/plain":"   id                   store_name  ... date_measured          country\n0   1   Cullen/Frost Bankers, Inc.  ...      4-2-2006   United States/\n1   2          Nordson Corporation  ...      4-1-2006          Britain\n2   3        Stag Industrial, Inc.  ...     12-9-2003    United States\n3   4          FIRST REPUBLIC BANK  ...      8-5-2006         Britain/\n4   5  Mercantile Bank Corporation  ...     21-1-1973   United Kingdom\n\n[5 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>store_name</th>\n      <th>store_email</th>\n      <th>department</th>\n      <th>income</th>\n      <th>date_measured</th>\n      <th>country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Cullen/Frost Bankers, Inc.</td>\n      <td>NaN</td>\n      <td>Clothing</td>\n      <td>$54438554.24</td>\n      <td>4-2-2006</td>\n      <td>United States/</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Nordson Corporation</td>\n      <td>NaN</td>\n      <td>Tools</td>\n      <td>$41744177.01</td>\n      <td>4-1-2006</td>\n      <td>Britain</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Stag Industrial, Inc.</td>\n      <td>NaN</td>\n      <td>Beauty</td>\n      <td>$36152340.34</td>\n      <td>12-9-2003</td>\n      <td>United States</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>FIRST REPUBLIC BANK</td>\n      <td>ecanadine3@fc2.com</td>\n      <td>Automotive</td>\n      <td>$8928350.04</td>\n      <td>8-5-2006</td>\n      <td>Britain/</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Mercantile Bank Corporation</td>\n      <td>NaN</td>\n      <td>Baby</td>\n      <td>$33552742.32</td>\n      <td>21-1-1973</td>\n      <td>United Kingdom</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":26}]},{"source":"1. Take a look at all the unique values in the \"country\" column. Then, convert the column to lowercase and remove any trailing white spaces.","metadata":{"id":"ItqLwumA16Wr"},"id":"fc205bb6-3e9e-4b23-8e1f-992d4a9259a5","cell_type":"markdown"},{"source":"countries = store_income_df.country.unique()\nprint(f\"There are {len(countries)} unique countries\")\ncountries","metadata":{"id":"sLkzt4Hr16Wr","executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1698429961878,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"countries = store_income_df.country.unique()\nprint(f\"There are {len(countries)} unique countries\")\ncountries","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"id":"6622e84e-418d-40ab-a39f-dc65e04acc4b","cell_type":"code","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":"There are 77 unique countries\n"},{"output_type":"execute_result","data":{"text/plain":"array(['United States/', 'Britain', ' United States', 'Britain/',\n       ' United Kingdom', 'U.K.', 'SA ', 'U.K/', 'America',\n       'United Kingdom', nan, 'united states', ' S.A.', 'England ', 'UK',\n       'S.A./', 'ENGLAND', 'BRITAIN', 'U.K', 'U.K ', 'America/', 'SA.',\n       'S.A. ', 'u.k', 'uk', ' ', 'UK.', 'England/', 'england',\n       ' Britain', 'united states of america', 'UK/', 'SA/', 'SA',\n       'England.', 'UNITED KINGDOM', 'America.', 'S.A..', 's.a.', ' U.K',\n       ' United States of America', 'Britain ', 'England', ' SA',\n       'United States of America.', 'United States of America/',\n       'United States.', 's. africasouth africa', ' England',\n       'United Kingdom ', 'United States of America ', ' UK',\n       'united kingdom', 'AMERICA', 'America ',\n       'UNITED STATES OF AMERICA', ' S. AfricaSouth Africa', 'america',\n       'S. AFRICASOUTH AFRICA', 'Britain.', '/', 'United Kingdom.',\n       'United States', ' America', 'UNITED STATES', 'sa',\n       'United States of America', 'UK ', 'United States ',\n       'S. AfricaSouth Africa/', 'S.A.', 'United Kingdom/',\n       'S. AfricaSouth Africa ', 'S. AfricaSouth Africa.',\n       'S. AfricaSouth Africa', '.', 'britain'], dtype=object)"},"metadata":{},"execution_count":27}]},{"source":"# Convert 'country' column to lowercase\nstore_income_df[\"country\"]=store_income_df[\"country\"].str.lower()\n\n# Remove trailing white space in 'country' column\nstore_income_df[\"country\"]=store_income_df[\"country\"].str.strip()\n\ncountries = store_income_df.country.unique()\nprint(f\"There are {len(countries)} countries\")\ncountries","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1698429961926,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Convert 'country' column to lowercase\nstore_income_df[\"country\"]=store_income_df[\"country\"].str.lower()\n\n# Remove trailing white space in 'country' column\nstore_income_df[\"country\"]=store_income_df[\"country\"].str.strip()\n\ncountries = store_income_df.country.unique()\nprint(f\"There are {len(countries)} countries\")\ncountries","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"cell_type":"code","id":"df3242c0-ac25-46df-9cf3-04df40af3cd3","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":"There are 37 countries\n"},{"output_type":"execute_result","data":{"text/plain":"array(['united states/', 'britain', 'united states', 'britain/',\n       'united kingdom', 'u.k.', 'sa', 'u.k/', 'america', nan, 's.a.',\n       'england', 'uk', 's.a./', 'u.k', 'america/', 'sa.', '', 'uk.',\n       'england/', 'united states of america', 'uk/', 'sa/', 'england.',\n       'america.', 's.a..', 'united states of america.',\n       'united states of america/', 'united states.',\n       's. africasouth africa', 'britain.', '/', 'united kingdom.',\n       's. africasouth africa/', 'united kingdom/',\n       's. africasouth africa.', '.'], dtype=object)"},"metadata":{},"execution_count":28}]},{"source":"2. Note that there should only be three separate countries. Eliminate all variations, so that 'South Africa', 'United Kingdom' and 'United States' are the only three countries.","metadata":{"id":"P6dcDc4P16Ws"},"id":"60242872-7c0d-4e3c-950e-f4e37735ce94","cell_type":"markdown"},{"source":"# Function to replace rows in the provided column of the provided DataFrame\n# that match the provided string above the provided ratio with the provided string\n\ndef replace_matches_in_column(df, column, string_to_match, min_ratio = 90):\n    # get a list of unique strings\n    strings = df[column].unique()\n    \n    # Get the top 13 closest matches from the input string\n    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n                                         limit=13, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n\n    # Only get matches with a ratio greater than 90\n    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n\n    # Get the rows of all the close matches in the dataframe\n    rows_with_matches = df[column].isin(close_matches)\n\n    # Replace all rows with close matches with the input matches \n    df.loc[rows_with_matches, column] = string_to_match\n    \n    print(\"All done!\")","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1698429961973,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Function to replace rows in the provided column of the provided DataFrame\n# that match the provided string above the provided ratio with the provided string\n\ndef replace_matches_in_column(df, column, string_to_match, min_ratio = 90):\n    # get a list of unique strings\n    strings = df[column].unique()\n    \n    # Get the top 13 closest matches from the input string\n    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n                                         limit=13, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n\n    # Only get matches with a ratio greater than 90\n    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n\n    # Get the rows of all the close matches in the dataframe\n    rows_with_matches = df[column].isin(close_matches)\n\n    # Replace all rows with close matches with the input matches \n    df.loc[rows_with_matches, column] = string_to_match\n    \n    print(\"All done!\")"},"cell_type":"code","id":"3ae0fa94-98f5-4a50-8fbf-f36fca34ec7a","execution_count":29,"outputs":[]},{"source":"replace_matches_in_column(df=store_income_df, column='country', string_to_match=\"united kingdom\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"united states\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"united states of america\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"africasouth\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"uk\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"u.k\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"sa\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"s.a\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"america\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"britain\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"england\")","metadata":{"executionCancelledAt":null,"executionTime":67,"lastExecutedAt":1698429962041,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"replace_matches_in_column(df=store_income_df, column='country', string_to_match=\"united kingdom\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"united states\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"united states of america\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"africasouth\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"uk\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"u.k\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"sa\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"s.a\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"america\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"britain\")\nreplace_matches_in_column(df=store_income_df, column='country', string_to_match=\"england\")","outputsMetadata":{"0":{"height":232,"type":"stream"}}},"cell_type":"code","id":"1a634ba4-5360-4527-8fd2-f4011aa43c06","execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":"All done!\nAll done!\nAll done!\nAll done!\nAll done!\nAll done!\nAll done!\nAll done!\nAll done!\nAll done!\nAll done!\n"}]},{"source":"# Get all the unique values in the 'country' column\ncountries = store_income_df['country'].unique()\n\nprint(f\"There are {len(countries)} unique countries\")\ncountries","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1698429962090,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Get all the unique values in the 'country' column\ncountries = store_income_df['country'].unique()\n\nprint(f\"There are {len(countries)} unique countries\")\ncountries","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"cell_type":"code","id":"842e53b7-2cd3-4381-a060-e55ca34b0ae1","execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":"There are 17 unique countries\n"},{"output_type":"execute_result","data":{"text/plain":"array(['united states', 'britain', 'united kingdom', 'u.k', 'sa',\n       'america', nan, 's.a', 'england', 'uk', '',\n       'united states of america', 's. africasouth africa', '/',\n       's. africasouth africa/', 's. africasouth africa.', '.'],\n      dtype=object)"},"metadata":{},"execution_count":31}]},{"source":"# Replace remaining values manually\nstore_income_df.replace({'uk':'united kingdom',\n                         'britain':'united kingdom',\n                         'u.k':'united kingdom',\n                         'england':'united kingdom',\n                        'united states of america':'united states',\n                         'america':'united states',\n                         'sa':'south africa',\n                         's.a':'south africa',\n                         's. africasouth africa':'south africa',\n                         's. africasouth africa/':'south africa',\n                         's. africasouth africa.':'south africa',\n                         '/':np.nan,\n                         '':np.nan,\n                         '.':np.nan\n                        }, inplace=True)\n\n# Get all the unique values in the 'country' column excluding empty cells\ncountries = store_income_df['country'].dropna().unique()\n\nprint(f\"There are {len(countries)} unique countries\")\ncountries","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1698429962142,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Replace remaining values manually\nstore_income_df.replace({'uk':'united kingdom',\n                         'britain':'united kingdom',\n                         'u.k':'united kingdom',\n                         'england':'united kingdom',\n                        'united states of america':'united states',\n                         'america':'united states',\n                         'sa':'south africa',\n                         's.a':'south africa',\n                         's. africasouth africa':'south africa',\n                         's. africasouth africa/':'south africa',\n                         's. africasouth africa.':'south africa',\n                         '/':np.nan,\n                         '':np.nan,\n                         '.':np.nan\n                        }, inplace=True)\n\n# Get all the unique values in the 'country' column excluding empty cells\ncountries = store_income_df['country'].dropna().unique()\n\nprint(f\"There are {len(countries)} unique countries\")\ncountries","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"cell_type":"code","id":"9622795b-8f41-4df7-bd03-d911cb0fe33d","execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":"There are 3 unique countries\n"},{"output_type":"execute_result","data":{"text/plain":"array(['united states', 'united kingdom', 'south africa'], dtype=object)"},"metadata":{},"execution_count":32}]},{"source":"3. Create a new column called `days_ago` in the DataFrame that is a copy of the 'date_measured' column but instead it is a number that shows how many days ago it was measured from the current date. Note that the current date can be obtained using `datetime.date.today()`.","metadata":{"id":"UJZDMTwP16Ws"},"id":"84a25fab-33cd-434c-84dc-65b4302329a3","cell_type":"markdown"},{"source":"# Create a column and convert data type for date_meeasured to 'datetime64'\nstore_income_df['date_parsed'] = pd.to_datetime(store_income_df['date_measured'], format='%d-%m-%Y')\n\n# Create a column for todays date\nstore_income_df['todays_date'] = datetime.date.today()\n\n# Create a column and convert data type for todays_date to 'datetime64'\nstore_income_df['todays_date_parsed'] = pd.to_datetime(store_income_df['todays_date'], format='%Y-%m-%d')\n\n# Create a column to get the number of days that shows how many\n# days ago it was measured from the current date.\nstore_income_df['days_ago'] = store_income_df['todays_date_parsed']-store_income_df['date_parsed']\n\nstore_income_df['days_ago'].head()","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1698429962194,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create a column and convert data type for date_meeasured to 'datetime64'\nstore_income_df['date_parsed'] = pd.to_datetime(store_income_df['date_measured'], format='%d-%m-%Y')\n\n# Create a column for todays date\nstore_income_df['todays_date'] = datetime.date.today()\n\n# Create a column and convert data type for todays_date to 'datetime64'\nstore_income_df['todays_date_parsed'] = pd.to_datetime(store_income_df['todays_date'], format='%Y-%m-%d')\n\n# Create a column to get the number of days that shows how many\n# days ago it was measured from the current date.\nstore_income_df['days_ago'] = store_income_df['todays_date_parsed']-store_income_df['date_parsed']\n\nstore_income_df['days_ago'].head()","outputsMetadata":{"0":{"height":207,"type":"dataFrame"}}},"cell_type":"code","id":"a548d57f-7f1d-4bc2-9f6d-c5e82cbd7039","execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":"0    6474 days\n1    6505 days\n2    7350 days\n3    6381 days\n4   18541 days\nName: days_ago, dtype: timedelta64[ns]"},"metadata":{},"execution_count":33}]}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}